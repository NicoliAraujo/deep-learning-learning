{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "from pyimagesearch.minigooglenet import MiniGoogLeNet\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 2\n",
    "output = 'multi_gpus2.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = num_gpus\n",
    "OUTPUT = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 70\n",
    "INIT_LR = 5e-3\n",
    " \n",
    "def poly_decay(epoch):\n",
    "    # initialize the maximum number of epochs, base learning rate,\n",
    "    # and power of the polynomial\n",
    "    maxEpochs = NUM_EPOCHS\n",
    "    baseLR = INIT_LR\n",
    "    power = 1.0\n",
    " \n",
    "    # compute the new learning rate based on polynomial decay\n",
    "    alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    " \n",
    "    # return the new learning rate\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training and testing data, converting the images from\n",
    "# integers to floats\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\")\n",
    "testX = testX.astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply mean subtraction to the data\n",
    "mean = np.mean(trainX, axis=0)\n",
    "trainX -= mean\n",
    "testX -= mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation and construct\n",
    "# the set of callbacks\n",
    "aug = ImageDataGenerator(width_shift_range=0.1,\n",
    "    height_shift_range=0.1, horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "callbacks = [LearningRateScheduler(poly_decay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training with 2 GPUs...\n"
     ]
    }
   ],
   "source": [
    "# check to see if we are compiling using just a single GPU\n",
    "if G <= 1:\n",
    "\tprint(\"[INFO] training with 1 GPU...\")\n",
    "\tmodel = MiniGoogLeNet.build(width=32, height=32, depth=3,\n",
    "\t\tclasses=10)\n",
    "# otherwise, we are compiling using multiple GPUs\n",
    "else:\n",
    "\tprint(\"[INFO] training with {} GPUs...\".format(G))\n",
    " \n",
    "\t# we'll store a copy of the model on *every* GPU and then combine\n",
    "\t# the results from the gradient updates on the CPU\n",
    "\twith tf.device(\"/device:GPU:1\"):\n",
    "\t\t# initialize the model\n",
    "\t\tmodel = MiniGoogLeNet.build(width=32, height=32, depth=3,\n",
    "\t\t\tclasses=10)\n",
    "\t\n",
    "\t# make the model parallel\n",
    "\t#model = multi_gpu_model(model, gpus=G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/70\n",
      " - 23s - loss: 1.5741 - acc: 0.4222 - val_loss: 1.4975 - val_acc: 0.4812\n",
      "Epoch 2/70\n",
      " - 20s - loss: 1.1750 - acc: 0.5777 - val_loss: 1.2422 - val_acc: 0.5772\n",
      "Epoch 3/70\n",
      " - 20s - loss: 0.9999 - acc: 0.6461 - val_loss: 1.0578 - val_acc: 0.6275\n",
      "Epoch 4/70\n",
      " - 20s - loss: 0.8915 - acc: 0.6878 - val_loss: 1.0262 - val_acc: 0.6569\n",
      "Epoch 5/70\n",
      " - 20s - loss: 0.8120 - acc: 0.7160 - val_loss: 0.9050 - val_acc: 0.6919\n",
      "Epoch 6/70\n",
      " - 21s - loss: 0.7382 - acc: 0.7436 - val_loss: 0.8390 - val_acc: 0.7027\n",
      "Epoch 7/70\n",
      " - 21s - loss: 0.6905 - acc: 0.7622 - val_loss: 0.7273 - val_acc: 0.7525\n",
      "Epoch 8/70\n",
      " - 21s - loss: 0.6420 - acc: 0.7781 - val_loss: 0.7346 - val_acc: 0.7479\n",
      "Epoch 9/70\n",
      " - 21s - loss: 0.5990 - acc: 0.7932 - val_loss: 0.8689 - val_acc: 0.7182\n",
      "Epoch 10/70\n",
      " - 21s - loss: 0.5668 - acc: 0.8045 - val_loss: 0.7045 - val_acc: 0.7558\n",
      "Epoch 11/70\n",
      " - 21s - loss: 0.5371 - acc: 0.8158 - val_loss: 0.6215 - val_acc: 0.7884\n",
      "Epoch 12/70\n",
      " - 21s - loss: 0.5125 - acc: 0.8242 - val_loss: 0.6328 - val_acc: 0.7866\n",
      "Epoch 13/70\n",
      " - 21s - loss: 0.4887 - acc: 0.8330 - val_loss: 0.7532 - val_acc: 0.7632\n",
      "Epoch 14/70\n",
      " - 21s - loss: 0.4709 - acc: 0.8383 - val_loss: 0.6815 - val_acc: 0.7873\n",
      "Epoch 15/70\n",
      " - 21s - loss: 0.4458 - acc: 0.8471 - val_loss: 0.4925 - val_acc: 0.8286\n",
      "Epoch 16/70\n",
      " - 21s - loss: 0.4312 - acc: 0.8530 - val_loss: 0.5772 - val_acc: 0.8095\n",
      "Epoch 17/70\n",
      " - 21s - loss: 0.4127 - acc: 0.8580 - val_loss: 0.5328 - val_acc: 0.8267\n",
      "Epoch 18/70\n",
      " - 21s - loss: 0.3976 - acc: 0.8645 - val_loss: 0.7515 - val_acc: 0.7623\n",
      "Epoch 19/70\n",
      " - 21s - loss: 0.3849 - acc: 0.8697 - val_loss: 0.5746 - val_acc: 0.8150\n",
      "Epoch 20/70\n",
      " - 21s - loss: 0.3759 - acc: 0.8709 - val_loss: 0.5672 - val_acc: 0.8120\n",
      "Epoch 21/70\n",
      " - 21s - loss: 0.3593 - acc: 0.8768 - val_loss: 0.5486 - val_acc: 0.8267\n",
      "Epoch 22/70\n",
      " - 21s - loss: 0.3445 - acc: 0.8815 - val_loss: 0.4467 - val_acc: 0.8523\n",
      "Epoch 23/70\n",
      " - 21s - loss: 0.3337 - acc: 0.8857 - val_loss: 0.5822 - val_acc: 0.8172\n",
      "Epoch 24/70\n",
      " - 21s - loss: 0.3210 - acc: 0.8895 - val_loss: 0.5770 - val_acc: 0.8205\n",
      "Epoch 25/70\n",
      " - 21s - loss: 0.3158 - acc: 0.8930 - val_loss: 0.5056 - val_acc: 0.8331\n",
      "Epoch 26/70\n",
      " - 21s - loss: 0.3046 - acc: 0.8947 - val_loss: 0.4764 - val_acc: 0.8467\n",
      "Epoch 27/70\n",
      " - 21s - loss: 0.2936 - acc: 0.8984 - val_loss: 0.5219 - val_acc: 0.8310\n",
      "Epoch 28/70\n",
      " - 21s - loss: 0.2844 - acc: 0.9014 - val_loss: 0.8487 - val_acc: 0.7666\n",
      "Epoch 29/70\n",
      " - 21s - loss: 0.2757 - acc: 0.9058 - val_loss: 0.6448 - val_acc: 0.8088\n",
      "Epoch 30/70\n",
      " - 21s - loss: 0.2665 - acc: 0.9079 - val_loss: 0.5241 - val_acc: 0.8353\n",
      "Epoch 31/70\n",
      " - 21s - loss: 0.2554 - acc: 0.9119 - val_loss: 0.5157 - val_acc: 0.8439\n",
      "Epoch 32/70\n",
      " - 21s - loss: 0.2522 - acc: 0.9127 - val_loss: 0.5636 - val_acc: 0.8346\n",
      "Epoch 33/70\n",
      " - 21s - loss: 0.2447 - acc: 0.9162 - val_loss: 0.4535 - val_acc: 0.8533\n",
      "Epoch 34/70\n",
      " - 21s - loss: 0.2347 - acc: 0.9189 - val_loss: 0.5486 - val_acc: 0.8378\n",
      "Epoch 35/70\n",
      " - 21s - loss: 0.2334 - acc: 0.9199 - val_loss: 0.4972 - val_acc: 0.8457\n",
      "Epoch 36/70\n",
      " - 21s - loss: 0.2219 - acc: 0.9252 - val_loss: 0.4329 - val_acc: 0.8650\n",
      "Epoch 37/70\n",
      " - 21s - loss: 0.2175 - acc: 0.9249 - val_loss: 0.4419 - val_acc: 0.8649\n",
      "Epoch 38/70\n",
      " - 21s - loss: 0.2066 - acc: 0.9288 - val_loss: 0.5773 - val_acc: 0.8275\n",
      "Epoch 39/70\n",
      " - 21s - loss: 0.1993 - acc: 0.9317 - val_loss: 0.4185 - val_acc: 0.8670\n",
      "Epoch 40/70\n",
      " - 21s - loss: 0.1954 - acc: 0.9319 - val_loss: 0.4154 - val_acc: 0.8737\n",
      "Epoch 41/70\n",
      " - 21s - loss: 0.1931 - acc: 0.9331 - val_loss: 0.7498 - val_acc: 0.8090\n",
      "Epoch 42/70\n",
      " - 21s - loss: 0.1862 - acc: 0.9360 - val_loss: 0.5990 - val_acc: 0.8277\n",
      "Epoch 43/70\n",
      " - 21s - loss: 0.1779 - acc: 0.9389 - val_loss: 0.4262 - val_acc: 0.8643\n",
      "Epoch 44/70\n",
      " - 21s - loss: 0.1732 - acc: 0.9411 - val_loss: 0.4173 - val_acc: 0.8739\n",
      "Epoch 45/70\n",
      " - 21s - loss: 0.1697 - acc: 0.9414 - val_loss: 0.4518 - val_acc: 0.8664\n",
      "Epoch 46/70\n",
      " - 21s - loss: 0.1605 - acc: 0.9452 - val_loss: 0.4786 - val_acc: 0.8618\n",
      "Epoch 47/70\n",
      " - 21s - loss: 0.1601 - acc: 0.9444 - val_loss: 0.4176 - val_acc: 0.8780\n",
      "Epoch 48/70\n",
      " - 22s - loss: 0.1537 - acc: 0.9461 - val_loss: 0.4448 - val_acc: 0.8697\n",
      "Epoch 49/70\n",
      " - 21s - loss: 0.1459 - acc: 0.9501 - val_loss: 0.4267 - val_acc: 0.8727\n",
      "Epoch 50/70\n",
      " - 21s - loss: 0.1461 - acc: 0.9502 - val_loss: 0.4200 - val_acc: 0.8794\n",
      "Epoch 51/70\n",
      " - 21s - loss: 0.1420 - acc: 0.9521 - val_loss: 0.4596 - val_acc: 0.8727\n",
      "Epoch 52/70\n",
      " - 21s - loss: 0.1345 - acc: 0.9541 - val_loss: 0.4316 - val_acc: 0.8734\n",
      "Epoch 53/70\n",
      " - 22s - loss: 0.1309 - acc: 0.9550 - val_loss: 0.4618 - val_acc: 0.8692\n",
      "Epoch 54/70\n",
      " - 22s - loss: 0.1280 - acc: 0.9568 - val_loss: 0.3991 - val_acc: 0.8808\n",
      "Epoch 55/70\n",
      " - 22s - loss: 0.1246 - acc: 0.9575 - val_loss: 0.4695 - val_acc: 0.8647\n",
      "Epoch 56/70\n",
      " - 21s - loss: 0.1171 - acc: 0.9603 - val_loss: 0.4666 - val_acc: 0.8694\n",
      "Epoch 57/70\n",
      " - 22s - loss: 0.1162 - acc: 0.9606 - val_loss: 0.4070 - val_acc: 0.8812\n",
      "Epoch 58/70\n",
      " - 22s - loss: 0.1140 - acc: 0.9610 - val_loss: 0.4170 - val_acc: 0.8806\n",
      "Epoch 59/70\n",
      " - 21s - loss: 0.1085 - acc: 0.9640 - val_loss: 0.4518 - val_acc: 0.8690\n",
      "Epoch 60/70\n",
      " - 22s - loss: 0.1079 - acc: 0.9641 - val_loss: 0.4351 - val_acc: 0.8736\n",
      "Epoch 61/70\n",
      " - 21s - loss: 0.1052 - acc: 0.9642 - val_loss: 0.4127 - val_acc: 0.8835\n",
      "Epoch 62/70\n",
      " - 22s - loss: 0.1011 - acc: 0.9665 - val_loss: 0.4049 - val_acc: 0.8810\n",
      "Epoch 63/70\n",
      " - 22s - loss: 0.1009 - acc: 0.9663 - val_loss: 0.3858 - val_acc: 0.8876\n",
      "Epoch 64/70\n",
      " - 22s - loss: 0.0956 - acc: 0.9688 - val_loss: 0.4103 - val_acc: 0.8809\n",
      "Epoch 65/70\n",
      " - 22s - loss: 0.0937 - acc: 0.9690 - val_loss: 0.3936 - val_acc: 0.8854\n",
      "Epoch 66/70\n",
      " - 22s - loss: 0.0914 - acc: 0.9703 - val_loss: 0.3771 - val_acc: 0.8903\n",
      "Epoch 67/70\n",
      " - 22s - loss: 0.0885 - acc: 0.9714 - val_loss: 0.3710 - val_acc: 0.8907\n",
      "Epoch 68/70\n",
      " - 22s - loss: 0.0891 - acc: 0.9711 - val_loss: 0.3727 - val_acc: 0.8907\n",
      "Epoch 69/70\n",
      " - 22s - loss: 0.0873 - acc: 0.9722 - val_loss: 0.3659 - val_acc: 0.8927\n",
      "Epoch 70/70\n",
      " - 22s - loss: 0.0837 - acc: 0.9726 - val_loss: 0.3630 - val_acc: 0.8934\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    " \n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "\taug.flow(trainX, trainY, batch_size=64 * G),\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tsteps_per_epoch=len(trainX) // (64 * G),\n",
    "\tepochs=NUM_EPOCHS,\n",
    "\tcallbacks=callbacks, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import numpy as np\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0', '/device:GPU:1']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the history object dictionary\n",
    "H = H.history\n",
    " \n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, len(H[\"loss\"]))\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H[\"val_loss\"], label=\"test_loss\")\n",
    "plt.plot(N, H[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, H[\"val_acc\"], label=\"test_acc\")\n",
    "plt.title(\"MiniGoogLeNet on CIFAR-10\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    " \n",
    "# save the figure\n",
    "plt.savefig(output)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
