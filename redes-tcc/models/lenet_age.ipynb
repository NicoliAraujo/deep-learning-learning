{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicoli/github/alexnet/data_generator/batch_generator.py:42: UserWarning: 'BeautifulSoup' module is missing. The XML-parser will be unavailable.\n",
      "  warnings.warn(\"'BeautifulSoup' module is missing. The XML-parser will be unavailable.\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_generator.batch_generator import BatchGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from models import LeNetRegressor\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/nicoli/github/ssd_keras/dataset/csv/imdb_csv/imdb_age_regression.csv')\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "cols = list(df.columns[1:])\n",
    "in_format = list(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BatchGenerator(box_output_format=cols)\n",
    "validation_dataset = BatchGenerator(box_output_format=cols)\n",
    "\n",
    "train_dataset.parse_csv(labels_filename='/home/nicoli/github/ssd_keras/dataset/csv/imdb_csv/imdb_age_regression_train_split_47950-70-10-20.csv', \n",
    "                        images_dir='/home/nicoli/github/ssd_keras/dataset/imdb-hand-crop',\n",
    "                        input_format=in_format)\n",
    "\n",
    "validation_dataset.parse_csv(labels_filename='/home/nicoli/github/ssd_keras/dataset/csv/imdb_csv/imdb_age_regression_val_split_47950-70-10-20.csv', \n",
    "                             images_dir='/home/nicoli/github/ssd_keras/dataset/imdb-hand-crop',\n",
    "                             input_format=in_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width, img_depth = (224,224,3)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "train_batch_size = 64\n",
    "shuffle = True\n",
    "ssd_train = False\n",
    "\n",
    "validation_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the dataset: 33565\n",
      "Number of images in the dataset: 4795\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = train_dataset.generate(batch_size=train_batch_size,\n",
    "                                         shuffle=shuffle,\n",
    "                                         ssd_train=ssd_train,\n",
    "                                         flip=0.5,\n",
    "                                         equalize=True,\n",
    "                                         divide_by_stddev=255,\n",
    "                                         returns={'processed_labels'},\n",
    "                                         resize=(img_height, img_width))\n",
    "\n",
    "validation_generator = validation_dataset.generate(batch_size=validation_batch_size,\n",
    "                                                   shuffle=shuffle,\n",
    "                                                   ssd_train=ssd_train,\n",
    "                                                   flip=0.5,\n",
    "                                                   equalize=True,\n",
    "                                                   divide_by_stddev=255,\n",
    "                                                   returns={'processed_labels'},\n",
    "                                                   resize=(img_height, img_width))\n",
    "\n",
    "print(\"Number of images in the dataset:\", train_dataset.get_n_samples())\n",
    "print(\"Number of images in the dataset:\", validation_dataset.get_n_samples())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = train_dataset.get_n_samples()/train_batch_size\n",
    "validation_steps = validation_dataset.get_n_samples()/validation_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicoli/github/alexnet/models.py:78: UserWarning: Considering a regression task with output function being 'relu'\n",
      "  warnings.warn('Considering a regression task with output function being \\'relu\\'')\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNetRegressor(1, img_width, img_height, img_depth, ativacao='lrelu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.00001, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger('callbacks/lenet/age/history-regression-fase2-2.csv', append=True, separator=',')\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='callbacks/lenet/age/class-weights-reg-fase2-2.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                           monitor='val_loss',\n",
    "                           verbose=1,\n",
    "                           save_best_only=False,\n",
    "                           period=1)\n",
    "callbacks=[checkpoint, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/100\n",
      "525/524 [==============================] - 1639s 3s/step - loss: 209.5940 - mean_absolute_error: 11.3658 - val_loss: 194.9050 - val_mean_absolute_error: 10.7846\n",
      "\n",
      "Epoch 00001: saving model to callbacks/lenet/age/class-weights-reg-fase2-2.01-194.91.hdf5\n",
      "Epoch 2/100\n",
      "417/524 [======================>.......] - ETA: 4:46 - loss: 189.3671 - mean_absolute_error: 10.8180"
     ]
    }
   ],
   "source": [
    "history = lenet.model.fit_generator(train_generator, epochs=epochs, \n",
    "                             steps_per_epoch=steps_per_epoch, \n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=validation_steps,\n",
    "                             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
