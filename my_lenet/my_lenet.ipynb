{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import h5py\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "#1)Load dataset\n",
    "dataset = datasets.fetch_mldata(\"MNIST Original\")\n",
    "print(dataset.data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = dataset.data.reshape((dataset.data.shape[0], 28, 28))\n",
    "print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[:, np.newaxis, :, :]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46900, 1, 28, 28) [4 9 1 ..., 5 7 4] (23100, 1, 28, 28) [7 4 1 ..., 2 4 2]\n",
      "[4 9 1 ..., 5 7 4]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#2)Dataset partition int train and test data\n",
    "#splits data into train and test by using test split of 33%\n",
    "#using split method, and normalizes the pixel values\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(\n",
    "    data / 255.0, dataset.target.astype(\"int\"), test_size=0.33)\n",
    "print(trainData.shape, trainLabels, testData.shape, testLabels)\n",
    "print(trainLabels)\n",
    "# transform the training and testing labels into vectors in the\n",
    "# range [0, classes] -- this generates a vector for each label,\n",
    "# where the index of the label is set to `1` and all other entries\n",
    "# to `0`; in the case of MNIST, there are 10 class labels\n",
    "trainLabels = np_utils.to_categorical(trainLabels, 10)\n",
    "print(trainLabels[0])\n",
    "testLabels = np_utils.to_categorical(testLabels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3)Loading model architecture\n",
    "(width, height, depth, classes) = (28, 28, 1, 10)\n",
    "print(width, height, depth, classes)\n",
    "opt = SGD(lr=0.01) #optimizer\n",
    "\n",
    "model = Sequential()#one layer after the other\n",
    "\n",
    "# first set of CONV => RELU => POOL\n",
    "model.add(Convolution2D(20, (5, 5), padding=\"same\",\n",
    "                        input_shape=(depth, height, width),\n",
    "                        data_format=\"channels_first\"))#you only have to declare data format on the first layer\n",
    "model.add(Activation(\"relu\"))#activation\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))#maxpooling--> 2x2 sliding window that walks a distance of 2 pixels to x and y\n",
    "\n",
    "# second set of CONV => RELU => POOL\n",
    "model.add(Convolution2D(50, (5, 5), padding=\"same\")) #extracts 50 5x5 filters, same input\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# softmax classifier--> only in the end. Its the NN\n",
    "model.add(Dense(classes))\n",
    "model.add(Activation(\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4)Compiling model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5)Training model\n",
    "model.fit(trainData, trainLabels, batch_size=128, nb_epoch=20,\n",
    "          verbose=1)\n",
    "\n",
    "(loss, accuracy) = model.evaluate(testData, testLabels,\n",
    "                                  batch_size=128, verbose=1)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "model = Sequential()#one layer after the other\n",
    "model.save_weights(\"lenet_weights.hdf5\", overwrite=True)\n",
    "\n",
    "model_json = model.to_json()\n",
    "print(model_json)\n",
    "with open(\"my_model.json\", \"w+\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
